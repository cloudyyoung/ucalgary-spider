{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1883,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.language import Language\n",
    "from spacy.tokens import Doc, Span, Token\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.pipeline import SpanRuler, EntityRuler\n",
    "from pymongo import MongoClient\n",
    "import re\n",
    "from nltk import Tree\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1884,
   "metadata": {},
   "outputs": [],
   "source": [
    "def letter_generator():\n",
    "    yield from itertools.cycle(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\")\n",
    "\n",
    "letters = letter_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1885,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to mongodb\n",
    "client = MongoClient(\"mongodb://root:password@localhost:27017/\")\n",
    "catalog = client.get_database(\"catalog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1886,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BIMA',\n",
       " 'IFPE',\n",
       " 'OBHR',\n",
       " 'HROD',\n",
       " 'IFPB',\n",
       " 'CMMB',\n",
       " 'SCPA',\n",
       " 'EAPP',\n",
       " 'APLA',\n",
       " 'ENEE',\n",
       " 'ALMC',\n",
       " 'LLAC',\n",
       " 'ENSF',\n",
       " 'IPHE',\n",
       " 'CEST',\n",
       " 'CAAP',\n",
       " 'EVDA',\n",
       " 'IFPX',\n",
       " 'ISEC',\n",
       " 'EESS',\n",
       " 'ASHA',\n",
       " 'SUSE',\n",
       " 'ENTI',\n",
       " 'COMS',\n",
       " 'MDPA',\n",
       " 'LWFT',\n",
       " 'STAS',\n",
       " 'BTMA',\n",
       " 'SEDV',\n",
       " 'SGMA',\n",
       " 'MDBT',\n",
       " 'ANME',\n",
       " 'MDPS',\n",
       " 'MGIS',\n",
       " 'EVDL',\n",
       " 'RMIN',\n",
       " 'EDTP',\n",
       " 'EVDP',\n",
       " 'PLMA',\n",
       " 'EDBT',\n",
       " 'GSXS',\n",
       " 'MUHL',\n",
       " 'MUTC',\n",
       " 'MHST',\n",
       " 'EALS',\n",
       " 'DEST',\n",
       " 'CMDA',\n",
       " 'MDGE',\n",
       " 'CMCL',\n",
       " 'MDCH',\n",
       " 'ENEN',\n",
       " 'ENMF',\n",
       " 'TDST',\n",
       " 'IDST',\n",
       " 'CORE',\n",
       " 'MDPR',\n",
       " 'BSEN',\n",
       " 'ENFD',\n",
       " 'SCMA',\n",
       " 'INTR',\n",
       " 'GRST',\n",
       " 'EDPS',\n",
       " 'BMEN',\n",
       " 'ENME',\n",
       " 'LAND',\n",
       " 'SUST',\n",
       " 'ENEL',\n",
       " 'COOP',\n",
       " 'LAST',\n",
       " 'ASL',\n",
       " 'COLT',\n",
       " 'TRAN',\n",
       " 'ENAE',\n",
       " 'ENGO',\n",
       " 'ENPE',\n",
       " 'ENSC',\n",
       " 'OPMA',\n",
       " 'ARST',\n",
       " 'INDL',\n",
       " 'ENCH',\n",
       " 'ENCM',\n",
       " 'SENG',\n",
       " 'EDER',\n",
       " 'NTVE',\n",
       " 'CTED',\n",
       " 'EVDS',\n",
       " 'REAL',\n",
       " 'UNEX',\n",
       " 'VETM',\n",
       " 'TAP',\n",
       " 'PHEN',\n",
       " 'SAST',\n",
       " 'ENDG',\n",
       " 'ENPH',\n",
       " 'CUSP',\n",
       " 'SASO',\n",
       " 'AMAT',\n",
       " 'EAST',\n",
       " 'HSOC',\n",
       " 'LEAD',\n",
       " 'MGST',\n",
       " 'TOUR',\n",
       " 'INDG',\n",
       " 'ENER',\n",
       " 'APSY',\n",
       " 'PHED',\n",
       " 'MUPF',\n",
       " 'RELS',\n",
       " 'ACSC',\n",
       " 'QUAC',\n",
       " 'ENCI',\n",
       " 'ENMG',\n",
       " 'POLI',\n",
       " 'STST',\n",
       " 'ACWR',\n",
       " 'CPSC',\n",
       " 'CNST',\n",
       " 'ATTH',\n",
       " 'PMAT',\n",
       " 'LWSO',\n",
       " 'MDPH',\n",
       " 'MUED',\n",
       " 'MDSC',\n",
       " 'AFST',\n",
       " 'ROST',\n",
       " 'PEAT',\n",
       " 'GNST',\n",
       " 'SOSC',\n",
       " 'WMST',\n",
       " 'DCED',\n",
       " 'NUOS',\n",
       " 'MRSC',\n",
       " 'ESCI',\n",
       " 'ISST',\n",
       " 'UBST',\n",
       " 'EASC',\n",
       " 'SPPH',\n",
       " 'PLBI',\n",
       " 'BIST',\n",
       " 'PPOL',\n",
       " 'ARCH',\n",
       " 'BCEM',\n",
       " 'ANTH',\n",
       " 'NEUR',\n",
       " 'ASPH',\n",
       " 'DATA',\n",
       " 'ARHI',\n",
       " 'MATH',\n",
       " 'SOWK',\n",
       " 'KNES',\n",
       " 'ARKY',\n",
       " 'LING',\n",
       " 'NANS',\n",
       " 'ENGG',\n",
       " 'STAT',\n",
       " 'ACCT',\n",
       " 'GOPH',\n",
       " 'INNO',\n",
       " 'PHIL',\n",
       " 'INTE',\n",
       " 'PSYC',\n",
       " 'UNIV',\n",
       " 'HUMN',\n",
       " 'EDUC',\n",
       " 'ASTR',\n",
       " 'ECON',\n",
       " 'MKTG',\n",
       " 'WELL',\n",
       " 'FINA',\n",
       " 'CHEM',\n",
       " 'GEOG',\n",
       " 'SOCI',\n",
       " 'PLUR',\n",
       " 'ETAS',\n",
       " 'JPNS',\n",
       " 'LANG',\n",
       " 'MDCN',\n",
       " 'PLAN',\n",
       " 'ECOL',\n",
       " 'NURS',\n",
       " 'PHYS',\n",
       " 'GLGY',\n",
       " 'HTST',\n",
       " 'RUSS',\n",
       " 'ENGL',\n",
       " 'SPAN',\n",
       " 'FNCE',\n",
       " 'ITAL',\n",
       " 'SCIE',\n",
       " 'BIOL',\n",
       " 'CHIN',\n",
       " 'ZOOL',\n",
       " 'NRSG',\n",
       " 'GERM',\n",
       " 'DSGN',\n",
       " 'FREN',\n",
       " 'SLAV',\n",
       " 'BOTA',\n",
       " 'LATI',\n",
       " 'DRAM',\n",
       " 'MUSI',\n",
       " 'DNCE',\n",
       " 'GREK',\n",
       " 'ERTH',\n",
       " 'ARTS',\n",
       " 'FILM',\n",
       " 'LAW',\n",
       " 'ART']"
      ]
     },
     "execution_count": 1886,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort by length of title\n",
    "subject_codes_docs = list(catalog.get_collection(\"subject_codes\").find())\n",
    "subject_codes_docs.sort(key=lambda x: len(x[\"title\"]), reverse=True)\n",
    "subject_codes_map = {doc[\"title\"]: doc[\"code\"] for doc in subject_codes_docs}\n",
    "subject_codes = [doc[\"code\"] for doc in subject_codes_docs]\n",
    "subject_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1887,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base patterns\n",
    "subject_code_regex = r\"([A-Z]{3,4})\"  # ART, MATH\n",
    "course_number_regex = r\"(\\d{2}-\\d|\\d{3}\\.\\d{1,2}|\\d{2,3})\"  # 101, 30-1, 599.45\n",
    "course_code_regex = rf\"{subject_code_regex} {course_number_regex}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1888,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_subject_code(sentence: str, loose: bool=False):\n",
    "\tfor subject_code in subject_codes_docs:\n",
    "\t\tif loose:\n",
    "\t\t\tsentence = re.sub(rf\"{subject_code[\"title\"]}\", rf\"{subject_code[\"code\"]}\", sentence)\n",
    "\t\telse:\n",
    "\t\t\tsentence = re.sub(rf\"{subject_code[\"title\"]} {course_number_regex}\", rf\"{subject_code[\"code\"]} \\1\", sentence)\n",
    "\treturn sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1889,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_replacement_letter():\n",
    "    # Create an iterator that cycles through the alphabet\n",
    "    for letter in itertools.cycle(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"):\n",
    "        yield letter\n",
    "\n",
    "replacement_letters = get_replacement_letter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1890,
   "metadata": {},
   "outputs": [],
   "source": [
    "Token.set_extension(\"course_code\", default=None, force=True)\n",
    "Doc.set_extension(\"replacements\", default=[], force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1891,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\", exclude=[\"ner\"])\n",
    "expand_nlp = spacy.load(\"en_core_web_sm\", exclude=[\"ner\"])\n",
    "constituency_nlp = spacy.load(\"en_core_web_sm\", exclude=[\"ner\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1892,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Language.component(\"set_custom_boundaries\")\n",
    "def set_custom_boundaries(doc):\n",
    "    for token in doc[:-1]:\n",
    "        if token.text == \";\":\n",
    "            doc[token.i + 1].is_sent_start = True\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1893,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Language.component(\"fix_ent_head\")\n",
    "def fix_ent_head(doc: Doc):\n",
    "    for sent in doc.sents:\n",
    "        for token in sent:\n",
    "            if token.pos_ == \"NUM\" and re.match(course_number_regex, token.text) is not None:\n",
    "                ancestors = list(filter(lambda x: x.text in subject_codes, token.ancestors))\n",
    "                ancestor = ancestors[0] if len(ancestors) > 0 else None\n",
    "\n",
    "                if ancestor:\n",
    "                    token.head = ancestor\n",
    "                    token._.course_code = f\"{ancestor.text}{token.text}\"\n",
    "\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1894,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Language.component(\"expand_course_code\")\n",
    "def expand_course_code(doc: Doc):\n",
    "    sent = \"\"\n",
    "\n",
    "    for token in doc:\n",
    "        if token.text in subject_codes:\n",
    "            continue\n",
    "\n",
    "        elif token.pos_ == \"NUM\" and re.match(course_number_regex, token.text) is not None:\n",
    "            left_tokens = [token.head] + list(reversed(list(doc[: token.i])))\n",
    "\n",
    "            for left_token in left_tokens:\n",
    "                if left_token.text in subject_codes:\n",
    "                    sent += left_token.text_with_ws\n",
    "                    break\n",
    "\n",
    "            sent += token.text_with_ws\n",
    "\n",
    "        else:\n",
    "            sent += token.text_with_ws\n",
    "\n",
    "    new_doc = nlp(sent)\n",
    "    new_doc.ents = []\n",
    "    return new_doc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1895,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entity_ruler: EntityRuler = expand_nlp.add_pipe(\"entity_ruler\")\n",
    "entity_ruler = EntityRuler(nlp)\n",
    "patterns = [\n",
    "    {\n",
    "        \"label\": \"COURSE\",\n",
    "        \"pattern\": [\n",
    "            {\"TEXT\": {\"REGEX\": subject_code_regex}},\n",
    "            {\"TEXT\": {\"REGEX\": course_number_regex}},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"REQUISITE\",\n",
    "        \"pattern\": [\n",
    "            {\"TEXT\": \"RQ\"},\n",
    "            {\"TEXT\": {\"REGEX\": \"[A-Z]\"}},\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "entity_ruler.clear()\n",
    "entity_ruler.add_patterns(patterns)\n",
    "\n",
    "@Language.component(\"detect_entity\")\n",
    "def detect_entity(doc: Doc):\n",
    "    ents = entity_ruler.match(doc)\n",
    "    doc.ents = ents\n",
    "    return doc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1896,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Language.component(\"merge_entity_spans\")\n",
    "def merge_entity_spans(doc: Doc):\n",
    "    with doc.retokenize() as retokenizer:\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ is not None:\n",
    "                retokenizer.merge(ent)\n",
    "    return doc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1897,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec',\n",
       " 'tagger',\n",
       " 'parser',\n",
       " 'attribute_ruler',\n",
       " 'lemmatizer',\n",
       " 'fix_ent_head',\n",
       " 'expand_course_code',\n",
       " 'detect_entity',\n",
       " 'merge_entity_spans']"
      ]
     },
     "execution_count": 1897,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expand_nlp.add_pipe(\"fix_ent_head\")\n",
    "expand_nlp.add_pipe(\"expand_course_code\")\n",
    "expand_nlp.add_pipe(\"detect_entity\")\n",
    "expand_nlp.add_pipe(\"merge_entity_spans\")\n",
    "\n",
    "expand_nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1898,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add(\n",
    "    \"X units of\",\n",
    "    [\n",
    "        [\n",
    "            {\"IS_DIGIT\": True},\n",
    "            {\"LEMMA\": \"unit\"},\n",
    "            {\"POS\": \"ADP\", \"OP\": \"+\"},\n",
    "            #\n",
    "            {\"ENT_TYPE\": \"COURSE\", \"OP\": \"?\"},\n",
    "            {\"TEXT\": {\"IN\": [\"and\", \"or\", \",\"]}, \"OP\": \"?\"},\n",
    "            #\n",
    "            #\n",
    "            {\"ENT_TYPE\": \"COURSE\", \"OP\": \"?\"},\n",
    "            {\"TEXT\": {\"IN\": [\"and\", \"or\", \",\"]}, \"OP\": \"?\"},\n",
    "            #\n",
    "            {\"ENT_TYPE\": \"COURSE\", \"OP\": \"?\"},\n",
    "            {\"TEXT\": {\"IN\": [\"and\", \"or\", \",\"]}, \"OP\": \"?\"},\n",
    "            #\n",
    "            {\"ENT_TYPE\": \"COURSE\", \"OP\": \"?\"},\n",
    "            {\"TEXT\": {\"IN\": [\"and\", \"or\", \",\"]}, \"OP\": \"?\"},\n",
    "            #\n",
    "            {\"ENT_TYPE\": \"COURSE\", \"OP\": \"?\"},\n",
    "            {\"TEXT\": {\"IN\": [\"and\", \"or\", \",\"]}, \"OP\": \"?\"},\n",
    "            #\n",
    "            {\"ENT_TYPE\": \"COURSE\", \"OP\": \"?\"},\n",
    "            {\"TEXT\": {\"IN\": [\"and\", \"or\", \",\"]}, \"OP\": \"?\"},\n",
    "            #\n",
    "            {\"ENT_TYPE\": \"COURSE\", \"OP\": \"?\"},\n",
    "            {\"TEXT\": {\"IN\": [\"and\", \"or\", \",\"]}, \"OP\": \"?\"},\n",
    "        ]\n",
    "    ],\n",
    "    greedy=\"LONGEST\",\n",
    ")\n",
    "\n",
    "matcher.add(\n",
    "    \"One of\",\n",
    "    [\n",
    "        [\n",
    "            {\"LEMMA\": \"one\"},\n",
    "            {\"POS\": \"ADP\", \"OP\": \"+\"},\n",
    "            {\"POS\": {\"NOT_IN\": [\"PUNC\"]}},\n",
    "            {\"TEXT\": {\"REGEX\": \"[A-Za-z, ]\"}, \"OP\": \"*\"},\n",
    "            {\"IS_SENT_START\": False},\n",
    "        ]\n",
    "    ],\n",
    "    greedy=\"LONGEST\",\n",
    ")\n",
    "\n",
    "matcher.add(\n",
    "    \"Consent of\",\n",
    "    [\n",
    "        [\n",
    "            {\"LEMMA\": \"consent\"},\n",
    "            {\"POS\": \"ADP\", \"OP\": \"+\"},\n",
    "            {\"TEXT\": {\"REGEX\": \"[A-Za-z, ]\"}, \"OP\": \"*\"},\n",
    "            {\"IS_SENT_START\": False},\n",
    "        ]\n",
    "    ],\n",
    "    greedy=\"LONGEST\",\n",
    ")\n",
    "\n",
    "matcher.add(\n",
    "    \"Admission to\",\n",
    "    [\n",
    "        [\n",
    "            {\"LEMMA\": \"admission\"},\n",
    "            {\"POS\": \"ADP\", \"OP\": \"+\"},\n",
    "            {\"TEXT\": {\"REGEX\": \"[A-Za-z, ]\", \"NOT_IN\": [\"and\", \"or\"]}, \"OP\": \"*\"},\n",
    "        ]\n",
    "    ],\n",
    "    greedy=\"LONGEST\",\n",
    ")\n",
    "\n",
    "matcher.add(\n",
    "    \"Both A and B\",\n",
    "    [\n",
    "        [\n",
    "            {\"LEMMA\": \"both\"},\n",
    "            {\"IS_ALPHA\": True},\n",
    "            {\"LEMMA\": \"and\"},\n",
    "            {\"IS_ALPHA\": True},\n",
    "            {\"IS_SENT_START\": False},\n",
    "        ]\n",
    "    ],\n",
    "    greedy=\"LONGEST\",\n",
    ")\n",
    "\n",
    "\n",
    "@Language.component(\"constitute_requisite\")\n",
    "def constitute_requisite(doc: Doc):\n",
    "    sent = doc.text\n",
    "    matches = matcher(doc)\n",
    "    spans = []\n",
    "\n",
    "    for match_id, start, end in matches:\n",
    "        letter = next(letters)\n",
    "        replacement = f\"RQ {letter}\"\n",
    "\n",
    "        span = doc[start:end]\n",
    "        spans.append((replacement, span))\n",
    "\n",
    "        sent = re.sub(re.escape(span.text), replacement, sent)\n",
    "\n",
    "    new_doc = nlp(sent)\n",
    "    new_doc._.replacements = spans\n",
    "    return new_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1899,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec',\n",
       " 'tagger',\n",
       " 'parser',\n",
       " 'attribute_ruler',\n",
       " 'lemmatizer',\n",
       " 'constitute_requisite',\n",
       " 'detect_entity',\n",
       " 'merge_entity_spans']"
      ]
     },
     "execution_count": 1899,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constituency_nlp.add_pipe(\"constitute_requisite\")\n",
    "constituency_nlp.add_pipe(\"detect_entity\")\n",
    "constituency_nlp.add_pipe(\"merge_entity_spans\")\n",
    "\n",
    "constituency_nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1900,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tok_format(tok):\n",
    "    # return \"_\".join([tok.orth_, tok.tag_])\n",
    "    return f\"{tok.orth_} ({tok.dep_})\"\n",
    "\n",
    "\n",
    "def to_nltk_tree(node):\n",
    "    if node.n_lefts + node.n_rights > 0:\n",
    "        return Tree(tok_format(node), [to_nltk_tree(child) for child in node.children])\n",
    "    else:\n",
    "        return tok_format(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1902,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: MATH 277 and PHYS 259 and admission to a program in Engineering.\n",
      "Expand  : MATH 277 and PHYS 259 and admission to a program in Engineering.\n",
      "Constituency: MATH 277 and PHYS 259 and RQ B.\n",
      "(MATH 277, PHYS 259, RQ B.)\n",
      "[('RQ B', admission to a program in Engineering)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    MATH 277\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">COURSE</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    PHYS 259\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">COURSE</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    RQ B.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">REQUISITE</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"511e2a75f7374964a483a3099a6a58b2-0\" class=\"displacy\" width=\"550\" height=\"287.0\" direction=\"ltr\" style=\"max-width: none; height: 287.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">MATH 277</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"150\">and</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"150\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"250\">PHYS 259</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"250\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">and</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"450\">RQ B.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"450\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-511e2a75f7374964a483a3099a6a58b2-0-0\" stroke-width=\"2px\" d=\"M62,152.0 62,135.33333333333334 144.0,135.33333333333334 144.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-511e2a75f7374964a483a3099a6a58b2-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M144.0,154.0 L148.0,146.0 140.0,146.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-511e2a75f7374964a483a3099a6a58b2-0-1\" stroke-width=\"2px\" d=\"M62,152.0 62,118.66666666666666 247.0,118.66666666666666 247.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-511e2a75f7374964a483a3099a6a58b2-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M247.0,154.0 L251.0,146.0 243.0,146.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-511e2a75f7374964a483a3099a6a58b2-0-2\" stroke-width=\"2px\" d=\"M262,152.0 262,135.33333333333334 344.0,135.33333333333334 344.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-511e2a75f7374964a483a3099a6a58b2-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M344.0,154.0 L348.0,146.0 340.0,146.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-511e2a75f7374964a483a3099a6a58b2-0-3\" stroke-width=\"2px\" d=\"M62,152.0 62,102.0 450.0,102.0 450.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-511e2a75f7374964a483a3099a6a58b2-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M450.0,154.0 L454.0,146.0 446.0,146.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sent = \"Actuarial Science 327; Statistics 323; 3 units from Mathematics 311, 313, 367 or 375; and 3 units from Computer Science 217, 231, 235 or Data Science 211.\"\n",
    "# sent = \"CPSC 457 and 3 units from SENG 300, 301 or ENSF 480; and admission to the Schulich School of Engineering.\"\n",
    "# sent = \"SGMA 395 or ENTI 317 or 381.\"\n",
    "# sent = \"One of FILM 321 or 323 and one of FILM 331 or 333.\"\n",
    "# sent = \"FILM 331 or 333.\"\n",
    "# sent = \"ENCI 473; and ENGG 319 or ENDG 319.\"\n",
    "# sent = \"3 units from ENCI 481, ENEE 377 or 519.09.\"\n",
    "# sent = \"ENEL 341, BMEN 327 or ENGG 225.\"\n",
    "# sent = \"ENEL 471; and one of BMEN 319 or ENGG 319 or ENEL 419.\"\n",
    "# sent = \"3 units from ENGG 319, ENDG 319 or ENEL 419.\"\n",
    "# sent = \"FILM 201 and 3 units from 305 or 321.\"\n",
    "# sent = \"INDG 201 and 3 units from INDG 303 or 345.\"\n",
    "# sent = \"One of GEOG 211, 251, 253, UBST 253, GLGY 201, 209; and consent of the Department.\"\n",
    "# sent = \"STAT 205 or 213; and admission to the Kinesiology Honours program; and consent of the Faculty.\"\n",
    "# sent = \"MATH 209 and admission to the Energy Engineering program.\"\n",
    "# sent = \"Both MATH 349 and 353; or both MATH 283 and 381; or MATH 267.\"\n",
    "# sent = \"MATH 431 or PMAT 431; MATH 429 or PMAT 429 or MATH 327 or PMAT 427.\"\n",
    "# sent = \"MATH 445 or 447; 3 units of Mathematics in the Field of Mathematics at the 400 level or above.\"\n",
    "# sent = \"MATH 383; and 6 units of Mathematics in the Field of Mathematics at the 400 level or above.\"\n",
    "# sent = \"MRSC 451 and consent of the Department.\"\n",
    "sent = \"Admission to the Haskayne School of Business and OBHR 317.\"\n",
    "sent = \"PHYS 211 or 221 or 227.\"\n",
    "sent = \"MATH 277 and PHYS 259 and admission to a program in Engineering.\"\n",
    "# sent = \"PHYS 341; and 3 units from CPSC 217, 231 or DATA 211.\"\n",
    "\n",
    "sent = replace_subject_code(sent)\n",
    "print(\"Original:\", sent)\n",
    "\n",
    "doc = expand_nlp(sent)\n",
    "print(\"Expand  :\", doc)\n",
    "\n",
    "\n",
    "doc = constituency_nlp(doc)\n",
    "print(\"Constituency:\", doc)\n",
    "\n",
    "print(doc.ents)\n",
    "print(doc._.replacements)\n",
    "\n",
    "\n",
    "displacy.render(doc, style=\"ent\", jupyter=True, options={\"compact\": True, \"distance\": 100})\n",
    "displacy.render(doc, style=\"dep\", jupyter=True, options={\"compact\": True, \"distance\": 100})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
